{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "'''import packages'''\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.feature_extraction.text import  TfidfVectorizer,TfidfTransformer\nfrom sklearn.feature_extraction.text import  CountVectorizer\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom time import time\nfrom sklearn import metrics\nfrom stopwordsiso import stopwords",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "'''import data'''\ntwenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)\ntwenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)\ndocs_test = twenty_test.data",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "'''Feature Extractors'''\nfeature_extractors = {\n    \"Counts\": CountVectorizer(),\n    \"TF\": TfidfVectorizer(use_idf=False),\n    \"TF-IDF\": TfidfVectorizer()\n}\n\n'''classifiers'''\nclassifiers = {\n    \"Naive Bayes\": MultinomialNB(),\n    \"Support Vector Machine\": SVC(kernel='linear'),\n    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n}",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "''' Comparing the performance of different feature extractors and classifiers '''\nfor feature_name, feature_extractor in feature_extractors.items():\n    for classifier_name, classifier in classifiers.items():\n        t0 = time()\n        print(f\"Training {classifier_name} classifier with {feature_name} feature...\")\n        pipeline = Pipeline([\n            ('vectorizer', feature_extractor),\n            ('classifier', classifier)\n        ])\n\n        pipeline.fit(twenty_train.data, twenty_train.target)\n        y_pred = pipeline.predict(twenty_test.data)\n\n        precision = precision_score(twenty_test.target, y_pred, average='weighted')\n        recall = recall_score(twenty_test.target, y_pred, average='weighted')\n        f1 = f1_score(twenty_test.target, y_pred, average='weighted')\n        t1 = time()\n        print(t1-t0)\n        print(f\"Precision for {classifier_name} classifier with {feature_name} feature: {precision:.2f}\")\n        print(f\"Recall for {classifier_name} classifier with {feature_name} feature: {recall:.2f}\")\n        print(f\"F1 score for {classifier_name} classifier with {feature_name} feature: {f1:.2f}\\n\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "'''Parameters'''\nLowercase = [True,False]\nngram_range = [(1, 1),(1, 2),(1, 3),(1, 4),(2, 2),(2, 3)]\nenglish_stopwords = stopwords([\"en\"])\nstop_words = [None,'english',list(english_stopwords)]\nmax_features = [None,500,2000,5000]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "'''Parameters Evaluation'''\n#Lowercase\nfor i in range(len(Lowercase)):\n    t0 = time()\n    text_clf = Pipeline([\n     ('vect', CountVectorizer(lowercase=Lowercase[i])),\n     ('tfidf', TfidfTransformer()),\n     ('clf', SVC(kernel='linear')),\n     ])\n    text_clf.fit(twenty_train.data, twenty_train.target)\n    predicted = text_clf.predict(docs_test)\n    t1 = time()\n    print(metrics.classification_report(twenty_test.target, predicted,\n     target_names=twenty_test.target_names))\n    print(t1-t0)\n\n#stop_words\nfor i in range(len(stop_words)):\n    t0 = time()\n    text_clf = Pipeline([\n     ('vect', CountVectorizer(stop_words=stop_words[i])),\n     ('tfidf', TfidfTransformer()),\n     ('clf', SVC(kernel='linear')),\n     ])\n    text_clf.fit(twenty_train.data, twenty_train.target)\n    predicted = text_clf.predict(docs_test)\n    t1 = time()\n    print(metrics.classification_report(twenty_test.target, predicted,\n     target_names=twenty_test.target_names))\n    print(t1-t0)\n    \n#ngram_range\nfor i in range(len(ngram_range)):\n    t0 = time()\n    text_clf = Pipeline([\n     ('vect', CountVectorizer(ngram_range=ngram_range[i])),\n     ('tfidf', TfidfTransformer()),\n     ('clf', SVC(kernel='linear')),\n     ])\n    text_clf.fit(twenty_train.data, twenty_train.target)\n    predicted = text_clf.predict(docs_test)\n    t1 = time()\n    print(metrics.classification_report(twenty_test.target, predicted,\n     target_names=twenty_test.target_names))\n    print(t1-t0)\n\n#max_features\nfor i in range(len(max_features)):\n    t0 = time()\n    text_clf = Pipeline([\n     ('vect', CountVectorizer(max_features=max_features[i])),\n     ('tfidf', TfidfTransformer()),\n     ('clf', SVC(kernel='linear')),\n     ])\n    text_clf.fit(twenty_train.data, twenty_train.target)\n    predicted = text_clf.predict(docs_test)\n    t1 = time()\n    print(metrics.classification_report(twenty_test.target, predicted,\n     target_names=twenty_test.target_names))\n    print(t1-t0)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}